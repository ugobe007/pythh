# ğŸ” Scraper Strategy Analysis & Recommendations

**Date**: December 2025  
**Status**: Active - 754 events/day, 36 startups/day  
**Health**: âš ï¸ Good data collection, but needs scale improvements

---

## Current State

### ğŸ“Š Performance Metrics (Last 24h)
| Metric | Value | Status |
|--------|-------|--------|
| Active RSS Sources | 84 | âœ… Good foundation |
| Events Collected | 754 | âš ï¸ Moderate volume |
| Startups Extracted | 36 | âŒ **Too low for scale** |
| Ontology Entities | 493 (204 active) | âœ… Good coverage |
| Scrape Frequency | Every 15 minutes | âœ… High cadence |
| Last Scrape Timestamp | **Broken** (epoch 0) | âŒ Needs fix |

### Conversion Funnel
```
754 events/day â†’ 36 startups/day = 4.8% conversion rate
```

**Problem**: At current scale:
- 36 startups/day = ~1,000 startups/month
- Industry leaders scrape 10,000-50,000 articles/day
- We're missing 95% of startup news

---

## Architecture Analysis

### Current Stack (Working)
```
PM2 Cron (every 15 min)
    â†“
ssot-rss-scraper.js (84 sources)
    â†“
frameParser.ts (SSOT parser)
    â†“
Phase A: Store events (100%)
Phase B: Graph joins (graph_safe=true only)
```

### Dynamic API Status

âœ… **API IS IMPLEMENTED** at [server/index.js:5814](server/index.js#L5814-L5833)

```javascript
POST /api/scrapers/run
{
  "scriptName": "scripts/core/ssot-rss-scraper.js",
  "description": "Manual RSS scrape trigger"
}
```

**Usage**: Admin dashboard can trigger scrapes on-demand via API  
**Status**: Functional, but underutilized (only manual triggers)

---

## Competitive Analysis: How Others Scale

### 1. **TechCrunch / VentureBeat** (50k+ articles/day)
| Strategy | Implementation |
|----------|----------------|
| **Multi-Tier Sources** | RSS + API integrations + Web scraping |
| **Dedicated Feeds** | 500+ RSS sources across regions/categories |
| **API Partnerships** | Direct feeds from PRNewswire, BusinessWire |
| **Web Scraping** | Puppeteer/Playwright for sites without RSS |
| **Social Monitoring** | Twitter/LinkedIn API for breaking news |

### 2. **Crunchbase** (10k+ companies/week)
| Strategy | Implementation |
|----------|----------------|
| **Crowdsourced Data** | User submissions + editorial review |
| **Investor Networks** | Direct feeds from VCs (portfolio pages) |
| **SEC Filings** | Automated Form D parsing (EDGAR API) |
| **News Aggregation** | 1000+ news sources globally |
| **Database Partnerships** | Clearbit, ZoomInfo integrations |

### 3. **YC Topcompanies** (verified startups)
| Strategy | Implementation |
|----------|----------------|
| **Application Data** | Direct from YC batch applications |
| **Portfolio Tracking** | Scrape 500+ VC portfolio pages weekly |
| **Public Databases** | Harmonized data from Crunchbase, AngelList, LinkedIn |
| **Founder Network** | Viral referral system for new startups |

### 4. **Hacker News/Product Hunt** (1k+ mentions/day)
| Strategy | Implementation |
|----------|----------------|
| **Community Submissions** | User-generated content |
| **API Access** | Algolia HN API, PH GraphQL API |
| **Real-Time Monitoring** | WebSockets for live updates |
| **Comment Mining** | Extract startup mentions from discussions |

---

## Gap Analysis: What We're Missing

| Source Type | Current | Should Have | Impact |
|-------------|---------|-------------|--------|
| **RSS Feeds** | 84 sources | 500+ sources | +10x events |
| **Web Scraping** | None | 50+ VC portfolios | +500 startups/week |
| **API Integrations** | None | 5-10 key APIs | +1000 startups/week |
| **Social Monitoring** | None | Twitter/LinkedIn | +200 events/day |
| **SEC Filings** | None | EDGAR API | +50 fundraises/week |
| **Community Input** | None | Submission form | +100 startups/week |

**Estimated Total**: 2,000-5,000 startups/week (vs current ~250)

---

## Recommendations: Scaling Strategy

### Phase 1: Expand RSS Sources (Quick Win - 2 weeks)
**Goal**: 84 â†’ 500+ sources

#### High-Value RSS Sources to Add
```javascript
// Regional Tech News (100+ sources)
- TechNode (Asia)
- EU-Startups (Europe)
- Disrupt Africa (Africa)
- LatAm.tech (Latin America)

// Industry Verticals (50+ sources)
- FinTech: FintechFutures, American Banker
- HealthTech: MobiHealthNews, HealthITNews
- Climate: GreenBiz, Canary Media
- AI/ML: VentureBeat AI, SyncedReview

// VC Firm Blogs (100+ sources)
- a16z, Sequoia, Accel, Bessemer (all have RSS)
- YC blog, First Round Review
- Regional VCs: 500 Startups, GGV Capital

// Accelerator News (50+ sources)
- Techstars blog feeds
- MassChallenge announcements
- Startup Grind events

// Business News (50+ sources)
- Forbes Startups, Inc Magazine
- Bloomberg Technology
- WSJ Venture Capital section
```

**Implementation**:
```sql
-- Script: scripts/add-rss-sources-batch.sql
INSERT INTO rss_sources (name, url, category, region, priority) VALUES
  ('TechNode', 'https://technode.com/feed/', 'tech-news', 'asia', 1),
  ('EU-Startups', 'https://www.eu-startups.com/feed/', 'tech-news', 'europe', 1),
  -- ... 400+ more
```

**Expected Impact**: 750 â†’ 5,000+ events/day (36 â†’ 240 startups/day)

---

### Phase 2: Portfolio Page Scraping (High Impact - 4 weeks)
**Goal**: Scrape 500+ VC portfolio pages weekly

#### Architecture
```javascript
// New file: scripts/portfolio-scraper.js
const puppeteer = require('puppeteer');

async function scrapeVCPortfolio(vcUrl) {
  const browser = await puppeteer.launch({ headless: true });
  const page = await browser.newPage();
  await page.goto(vcUrl);
  
  // Extract company names, descriptions, logos
  const companies = await page.evaluate(() => {
    return Array.from(document.querySelectorAll('.portfolio-company')).map(el => ({
      name: el.querySelector('.company-name')?.textContent,
      description: el.querySelector('.company-desc')?.textContent,
      website: el.querySelector('a')?.href,
      logo: el.querySelector('img')?.src
    }));
  });
  
  await browser.close();
  return companies;
}
```

#### Target VCs (Top 500)
- **Tier 1** (50 firms): a16z, Sequoia, Accel, Bessemer, etc.
- **Tier 2** (200 firms): Regional leaders
- **Tier 3** (250 firms): Emerging VCs, angels

**Implementation Timeline**:
- Week 1: Build generic scraper with selectors for top 10 VCs
- Week 2: Map 500 VC portfolio page structures
- Week 3: Deploy scraper with error handling/retry logic
- Week 4: Schedule weekly runs via PM2

**Expected Impact**: +500 startups/week (validated by VC association)

---

### Phase 3: API Integrations (Highest Quality - 6 weeks)
**Goal**: Integrate 5-10 high-quality APIs

#### Priority APIs
| API | Cost | Coverage | Quality | Integration Effort |
|-----|------|----------|---------|-------------------|
| **Crunchbase** | $49/mo | 1M+ companies | â­â­â­â­â­ | 2 weeks |
| **AngelList** | Free | 500k+ startups | â­â­â­â­ | 1 week |
| **Product Hunt** | Free | 100k+ products | â­â­â­â­ | 1 week |
| **EDGAR (SEC)** | Free | All Form D filings | â­â­â­â­â­ | 3 weeks |
| **Clearbit** | $99/mo | Enrichment data | â­â­â­â­ | 2 weeks |
| **LinkedIn** | Enterprise | People data | â­â­â­â­â­ | 4 weeks |
| **Twitter API** | $100/mo | Real-time mentions | â­â­â­ | 2 weeks |
| **Hacker News** | Free (Algolia) | YC community | â­â­â­â­ | 1 week |

#### Example: Crunchbase Integration
```javascript
// New file: scripts/integrations/crunchbase-sync.js
const axios = require('axios');

async function syncCrunchbaseStartups() {
  const response = await axios.get('https://api.crunchbase.com/api/v4/searches/organizations', {
    headers: { 'X-cb-user-key': process.env.CRUNCHBASE_API_KEY },
    params: {
      field_ids: ['name', 'short_description', 'founded_on', 'num_employees'],
      query: [{ type: 'predicate', field_id: 'founded_on', operator_id: 'gte', values: ['2023-01-01'] }]
    }
  });
  
  // Upsert to startup_uploads
  for (const org of response.data.entities) {
    await supabase.from('startup_uploads').upsert({
      name: org.properties.name,
      description: org.properties.short_description,
      source: 'crunchbase',
      crunchbase_id: org.uuid,
      status: 'pending' // Queue for GOD scoring
    });
  }
}
```

**Expected Impact**: +1,000 startups/week (highest quality, verified data)

---

### Phase 4: Social Media Monitoring (Real-Time - 4 weeks)
**Goal**: Monitor Twitter/LinkedIn for startup mentions

#### Architecture
```javascript
// New file: scripts/social-monitor.js
const { TwitterApi } = require('twitter-api-v2');

const twitterClient = new TwitterApi(process.env.TWITTER_BEARER_TOKEN);

async function monitorStartupMentions() {
  const stream = await twitterClient.v2.searchStream({
    'tweet.fields': ['author_id', 'created_at'],
    expansions: ['author_id']
  });
  
  // Add rules for startup indicators
  await twitterClient.v2.updateStreamRules({
    add: [
      { value: 'launched OR "we built" OR "our startup" OR "seed round"', tag: 'startup-launches' },
      { value: 'raised OR funding OR Series A OR seed', tag: 'funding-news' }
    ]
  });
  
  stream.on('data', async tweet => {
    // Parse tweet, extract startup mentions
    // Store to discovered_startups for review
  });
}
```

**Expected Impact**: +200 events/day (real-time startup news)

---

### Phase 5: Community Submissions (Viral Growth - 2 weeks)
**Goal**: Enable founder self-submissions

#### Simple Form
```typescript
// Add to frontend: src/pages/SubmitStartup.tsx
<form onSubmit={handleSubmit}>
  <input name="startup_name" placeholder="Your Startup Name" />
  <input name="website" placeholder="Website URL" />
  <textarea name="description" placeholder="What do you build?" />
  <input name="founder_email" placeholder="Your Email" />
  <button>Submit for Review</button>
</form>
```

**Incentive**: "Get matched with VCs in 24 hours"

**Expected Impact**: +100 startups/week (founder-submitted, high intent)

---

## Implementation Priorities

### Immediate (Week 1-2)
1. âœ… Fix `last_scraped` timestamp bug in scraper
2. ğŸš€ Add 100 high-value RSS sources (TechCrunch, EU-Startups, regional)
3. ğŸš€ Restart stopped PM2 processes (match-queue-processor, match-regenerator)

### Short-Term (Week 3-6)
4. ğŸŒ Build portfolio page scraper (target 50 top VCs)
5. ğŸ”Œ Integrate Hacker News API (free, 1-week effort)
6. ğŸ“ Add founder submission form

### Medium-Term (Week 7-12)
7. ğŸ”Œ Integrate Crunchbase API (paid, $49/mo)
8. ğŸ”Œ Integrate Product Hunt API (free)
9. ğŸ” Deploy Twitter monitoring stream

### Long-Term (Month 4+)
10. ğŸ”Œ EDGAR SEC filings (Form D parser)
11. ğŸ”Œ LinkedIn enrichment API
12. ğŸ¤– ML-powered entity linking (dedupe startups across sources)

---

## Cost Projection

| Item | Monthly Cost | Annual Cost |
|------|-------------|-------------|
| **Current** (84 RSS sources) | $0 | $0 |
| Crunchbase API | $49 | $588 |
| Twitter API (Basic) | $100 | $1,200 |
| Clearbit Enrichment | $99 | $1,188 |
| Puppeteer Cloud (ScrapingBee) | $49 | $588 |
| **Total** | **$297** | **$3,564** |

**ROI**: $297/mo â†’ 5,000 startups/week â†’ 20,000/month  
**Cost per startup**: $0.015 (1.5 cents)

---

## Ontology & Parsing Improvements

### Current Issues
1. **Ontology Filtering Too Early**: Fixed! Parser now checks ontology AFTER generic filters
2. **Low graph_safe Rate**: Only ~5% of events create graph joins
3. **Entity Quality**: "Show", "Europe" were passing through (now fixed)

### Recommended Enhancements

#### 1. Multi-Pass Entity Extraction
```typescript
// Enhance frameParser.ts with second-pass extraction
function extractEntitiesMultiPass(text: string) {
  // Pass 1: NER (Named Entity Recognition)
  const entities = nlp(text).people().out('array'); // Founders
  const orgs = nlp(text).organizations().out('array'); // Startups
  
  // Pass 2: Pattern matching
  const funding = text.match(/raised \$(\d+[MBK])/gi); // "$5M raised"
  const series = text.match(/Series [A-D]/gi); // "Series A"
  
  // Pass 3: Ontology validation
  return entities.filter(e => isInOntology(e) || hasHighConfidence(e));
}
```

#### 2. Confidence Scoring
```typescript
// Add confidence scores to entities
interface Entity {
  name: string;
  type: 'STARTUP' | 'INVESTOR' | 'PERSON';
  confidence: number; // 0-100
  sources: string[]; // ['ontology', 'ner', 'pattern']
}

// Only graph_safe if confidence >= 70
```

#### 3. Active Learning Pipeline
```javascript
// New: scripts/ml-ontology-agent.js (already in PM2!)
// Runs every 6 hours, auto-learns entities from events

// Flow:
Events (FILTERED) â†’ Extract novel entities â†’ Classify via GPT-4 â†’ Add to ontology (if confidence >= 85%)
```

**Status**: âœ… Already implemented! Running in PM2 as `ml-ontology-agent`

#### 4. Deduplication Layer
```typescript
// Problem: Same startup from multiple sources (TechCrunch + Crunchbase + Twitter)
// Solution: Entity linking via fuzzy matching + website URL

async function deduplicateStartup(name: string, website: string) {
  // Check if startup already exists
  const existing = await supabase
    .from('startup_uploads')
    .select('id, name, website')
    .or(`name.ilike.%${name}%,website.eq.${website}`)
    .limit(1);
  
  if (existing.data?.length > 0) {
    // Merge data, increment mention count
    return existing.data[0].id;
  }
  
  // New startup, create record
  return createNewStartup({ name, website });
}
```

---

## Monitoring & Alerts

### Health Dashboard Enhancement
**Add to**: [src/pages/SystemHealthDashboard.tsx](src/pages/SystemHealthDashboard.tsx)

```typescript
// New metrics to track
interface ScraperHealth {
  eventsPerDay: number; // Current: 754
  startupsPerDay: number; // Current: 36
  conversionRate: number; // 4.8%
  sourceCount: number; // 84
  sourceErrorRate: number; // % of sources failing
  avgParseTime: number; // Latency metric
  graphSafeRate: number; // % of events creating joins
}

// Alert thresholds
const THRESHOLDS = {
  MIN_EVENTS_PER_DAY: 500,
  MIN_STARTUPS_PER_DAY: 30,
  MAX_ERROR_RATE: 0.1, // 10%
  MIN_GRAPH_SAFE_RATE: 0.05 // 5%
};
```

### PM2 Process Health
```bash
# Add to system-guardian.js checks
pm2 logs rss-scraper --lines 100 --nostream | grep "ERROR"
pm2 logs ml-ontology-agent --lines 100 --nostream | grep "ERROR"
```

---

## Immediate Action Items

### ğŸ”§ Bug Fixes (TODAY)
1. **Fix last_scraped timestamp** in [scripts/core/ssot-rss-scraper.js](scripts/core/ssot-rss-scraper.js)
   - Issue: Shows epoch 0 (12/31/1969)
   - Fix: Update `rss_sources.last_scraped` after each scrape
   ```javascript
   await supabase
     .from('rss_sources')
     .update({ last_scraped: new Date().toISOString() })
     .eq('id', source.id);
   ```

2. **Restart stopped PM2 processes**
   ```bash
   pm2 restart match-queue-processor
   pm2 restart match-regenerator
   pm2 restart ml-training-scheduler
   ```

### ğŸš€ Quick Wins (THIS WEEK)
3. **Add 100 high-value RSS sources**
   - Focus: Regional tech news (Asia, Europe, LatAm)
   - Use script: `scripts/add-rss-sources-batch.sql`

4. **Validate Dynamic API**
   - Test: `POST /api/scrapers/run`
   - Add admin UI button to trigger manual scrapes

5. **Monitor ML Ontology Agent**
   - Check logs: `pm2 logs ml-ontology-agent --lines 50`
   - Verify auto-learning is working (runs every 6h)

---

## Success Metrics (30-Day Goals)

| Metric | Current | Target | Status |
|--------|---------|--------|--------|
| RSS Sources | 84 | 500 | ğŸ”´ 16% |
| Events/Day | 754 | 5,000 | ğŸ”´ 15% |
| Startups/Day | 36 | 240 | ğŸ”´ 15% |
| Conversion Rate | 4.8% | 5% | ğŸŸ¡ 96% |
| API Integrations | 0 | 3 | ğŸ”´ 0% |
| Portfolio Scrapers | 0 | 50 | ğŸ”´ 0% |
| Data Quality (graph_safe) | ~5% | 10% | ğŸ”´ 50% |

**Overall Health**: ğŸŸ¡ **Stable but needs scale improvements**

---

## Conclusion

### What's Working âœ…
- RSS scraper architecture (SSOT parser)
- PM2 automation (15-min scrape cadence)
- ML ontology learning (auto-runs every 6h)
- Dynamic API (`/api/scrapers/run`)

### What Needs Improvement âš ï¸
- **Scale**: 36 startups/day is 10x too low
- **Source diversity**: Only RSS (need APIs, web scraping, social)
- **Monitoring**: last_scraped timestamp broken
- **Process stability**: Some PM2 processes stopped

### Next Steps ğŸ¯
1. Fix bugs (timestamp, restart processes) - **TODAY**
2. Add 100 RSS sources - **THIS WEEK**
3. Build portfolio scraper - **NEXT 4 WEEKS**
4. Integrate Hacker News + Product Hunt APIs - **NEXT 6 WEEKS**
5. Deploy Twitter monitoring - **NEXT 8 WEEKS**

**Target**: 5,000 startups/week by end of Q1 2026

---

*Last updated: December 2025*
